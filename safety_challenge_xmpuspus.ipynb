{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety\n",
    "### Based on telematics data, how might we detect if the driver is driving dangerously?  \n",
    "Given the telematics data for each trip and the label if the trip is tagged as dangerous driving, derive a model that can detect dangerous driving trips.\n",
    "\n",
    "Submission by: Xavier M. Puspus  \n",
    "Email: xpuspus@gmail.com  \n",
    "Country: Philippines  \n",
    "\n",
    "The given dataset contains telematics data during trips (bookingID). Each trip will be assigned with label 1 or 0 in a separate label file to indicate dangerous driving. Pls take note that dangerous drivings are labelled per trip, while each trip could contain thousands of telematics data points. participants are supposed to create the features based on the telematics data before training models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload dependencies dynamically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from utils.utils import load_from_directory, process_data, show_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix as cf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from imblearn.over_sampling import SMOTE as sm\n",
    "from sklearn.metrics import roc_curve as roc\n",
    "from sklearn.metrics import auc as auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place data in directory data/\n",
    "FEATURES_PATH = 'data/safety/features'\n",
    "LABELS_PATH = 'data/safety/labels'\n",
    "\n",
    "# Load data\n",
    "features_df = load_from_directory(FEATURES_PATH)\n",
    "features_df = features_df.sort_values(['bookingID', 'second'])#.set_index('second')\n",
    "labels_df = load_from_directory(LABELS_PATH)\n",
    "\n",
    "# We groupby and sum labels to account for bookings with multiple labels (defaulting to dangerous)\n",
    "labels_df = labels_df.groupby('bookingID').max().reset_index()\n",
    "\n",
    "all_data = pd.merge(features_df, labels_df, on='bookingID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Bearing</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>second</th>\n",
       "      <th>Speed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>0.818112</td>\n",
       "      <td>-9.941461</td>\n",
       "      <td>-2.014999</td>\n",
       "      <td>-0.016245</td>\n",
       "      <td>-0.094040</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.442991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>0.546405</td>\n",
       "      <td>-9.835590</td>\n",
       "      <td>-2.038925</td>\n",
       "      <td>-0.047092</td>\n",
       "      <td>-0.078874</td>\n",
       "      <td>0.043187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.706207</td>\n",
       "      <td>-9.270792</td>\n",
       "      <td>-1.209448</td>\n",
       "      <td>-0.028965</td>\n",
       "      <td>-0.032652</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.416705</td>\n",
       "      <td>-9.548032</td>\n",
       "      <td>-1.860977</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.025753</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.598145</td>\n",
       "      <td>-9.853534</td>\n",
       "      <td>-1.378574</td>\n",
       "      <td>-0.014297</td>\n",
       "      <td>-0.046206</td>\n",
       "      <td>0.021902</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bookingID  Accuracy     Bearing  acceleration_x  acceleration_y  \\\n",
       "0          0      12.0  143.298294        0.818112       -9.941461   \n",
       "1          0       8.0  143.298294        0.546405       -9.835590   \n",
       "2          0       8.0  143.298294       -1.706207       -9.270792   \n",
       "3          0       8.0  143.298294       -1.416705       -9.548032   \n",
       "4          0       8.0  143.298294       -0.598145       -9.853534   \n",
       "\n",
       "   acceleration_z    gyro_x    gyro_y    gyro_z  second     Speed  label  \n",
       "0       -2.014999 -0.016245 -0.094040  0.070732     0.0  3.442991      0  \n",
       "1       -2.038925 -0.047092 -0.078874  0.043187     1.0  0.228454      0  \n",
       "2       -1.209448 -0.028965 -0.032652  0.015390     2.0  0.228454      0  \n",
       "3       -1.860977 -0.022413  0.005049 -0.025753     3.0  0.228454      0  \n",
       "4       -1.378574 -0.014297 -0.046206  0.021902     4.0  0.228454      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bookingID', 'Accuracy', 'Bearing', 'acceleration_x', 'acceleration_y',\n",
       "       'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z', 'second', 'Speed',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineer Data\n",
    "all_data['acceleration'] = (all_data['acceleration_x']**2 + \n",
    "                            all_data['acceleration_y']**2 + \n",
    "                            all_data['acceleration_z']**2).apply(lambda x: np.sqrt(x))\n",
    "\n",
    "all_data['gyro'] = (all_data['gyro_x']**2 + \n",
    "                            all_data['gyro_y']**2 + \n",
    "                            all_data['gyro_z']**2).apply(lambda x: np.sqrt(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Bookings to Train and Test\n",
    "n_ratio = 0.7\n",
    "n_ids = labels_df.shape[0]\n",
    "\n",
    "# Get Train-Test IDs\n",
    "train_ids = pd.DataFrame(labels_df.bookingID[:int(n_ids*n_ratio)])\n",
    "test_ids = pd.DataFrame(labels_df.bookingID[int(n_ids*n_ratio):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features for train-test ids\n",
    "train_df = pd.merge(train_ids, all_data, on='bookingID', how='inner')\n",
    "test_df = pd.merge(test_ids, all_data, on='bookingID', how='inner')\n",
    "\n",
    "# Get labels for train-test ids\n",
    "train_label = pd.merge(train_ids, labels_df, on='bookingID', how='inner')\n",
    "test_label = pd.merge(test_ids, labels_df, on='bookingID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11246691, 14), (4888870, 14), (14000, 2), (6000, 2))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get df sizes\n",
    "train_df.shape, test_df.shape, train_label.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train-test Columns\n",
    "feature_columns = ['Accuracy', 'Bearing', 'acceleration_x', 'acceleration_y',\n",
    "                    'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z', 'second', 'Speed']\n",
    "label_column = ['label']\n",
    "\n",
    "# Get train-test features and labels only\n",
    "# train_feats = train_df[feature_columns]\n",
    "# test_feats = test_df[feature_columns]\n",
    "\n",
    "# Feature Engineer Train-Test features\n",
    "train_feats = process_data(train_df)\n",
    "test_feats = process_data(test_df)\n",
    "\n",
    "train_lbl = train_label[label_column]\n",
    "test_lbl = test_label[label_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14000, 1320), (14000, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.shape, train_lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xpuspus/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Oversample Minority in train set\n",
    "sm_ = sm(random_state = 42)\n",
    "X_train_res, y_train_res = sm_.fit_sample(train_feats, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21340, 1320), (21340,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_res.shape, y_train_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from resampled feature train set\n",
    "X_train_res_df = pd.DataFrame(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = MLPClassifier((256, 128, 64), random_state=42, verbose=1, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.41905530\n",
      "Validation score: 0.526242\n",
      "Iteration 2, loss = 0.77602333\n",
      "Validation score: 0.622306\n",
      "Iteration 3, loss = 0.67022786\n",
      "Validation score: 0.603561\n",
      "Iteration 4, loss = 0.64453347\n",
      "Validation score: 0.664480\n",
      "Iteration 5, loss = 0.61169415\n",
      "Validation score: 0.685098\n",
      "Iteration 6, loss = 0.58216474\n",
      "Validation score: 0.610590\n",
      "Iteration 7, loss = 0.55168076\n",
      "Validation score: 0.705248\n",
      "Iteration 8, loss = 0.49699708\n",
      "Validation score: 0.608716\n",
      "Iteration 9, loss = 0.48347671\n",
      "Validation score: 0.721181\n",
      "Iteration 10, loss = 0.43215887\n",
      "Validation score: 0.630272\n",
      "Iteration 11, loss = 0.39878368\n",
      "Validation score: 0.643861\n",
      "Iteration 12, loss = 0.41391980\n",
      "Validation score: 0.750703\n",
      "Iteration 13, loss = 0.34725292\n",
      "Validation score: 0.721649\n",
      "Iteration 14, loss = 0.31770138\n",
      "Validation score: 0.735239\n",
      "Iteration 15, loss = 0.30512780\n",
      "Validation score: 0.783974\n",
      "Iteration 16, loss = 0.25871267\n",
      "Validation score: 0.650890\n",
      "Iteration 17, loss = 0.30998096\n",
      "Validation score: 0.752577\n",
      "Iteration 18, loss = 0.26346790\n",
      "Validation score: 0.720712\n",
      "Iteration 19, loss = 0.21032638\n",
      "Validation score: 0.747891\n",
      "Iteration 20, loss = 0.19876065\n",
      "Validation score: 0.748828\n",
      "Iteration 21, loss = 0.16280597\n",
      "Validation score: 0.800843\n",
      "Iteration 22, loss = 0.17563170\n",
      "Validation score: 0.803187\n",
      "Iteration 23, loss = 0.16665238\n",
      "Validation score: 0.764292\n",
      "Iteration 24, loss = 0.14605942\n",
      "Validation score: 0.797563\n",
      "Iteration 25, loss = 0.13201370\n",
      "Validation score: 0.783505\n",
      "Iteration 26, loss = 0.10916758\n",
      "Validation score: 0.720712\n",
      "Iteration 27, loss = 0.18074690\n",
      "Validation score: 0.741799\n",
      "Iteration 28, loss = 0.28396597\n",
      "Validation score: 0.800375\n",
      "Iteration 29, loss = 0.16458224\n",
      "Validation score: 0.825679\n",
      "Iteration 30, loss = 0.09343218\n",
      "Validation score: 0.791003\n",
      "Iteration 31, loss = 0.08863464\n",
      "Validation score: 0.774133\n",
      "Iteration 32, loss = 0.07122748\n",
      "Validation score: 0.844892\n",
      "Iteration 33, loss = 0.08895412\n",
      "Validation score: 0.801781\n",
      "Iteration 34, loss = 0.08531890\n",
      "Validation score: 0.789597\n",
      "Iteration 35, loss = 0.07616900\n",
      "Validation score: 0.835052\n",
      "Iteration 36, loss = 0.07843686\n",
      "Validation score: 0.828491\n",
      "Iteration 37, loss = 0.15464678\n",
      "Validation score: 0.823336\n",
      "Iteration 38, loss = 0.10107783\n",
      "Validation score: 0.802249\n",
      "Iteration 39, loss = 0.15364243\n",
      "Validation score: 0.808341\n",
      "Iteration 40, loss = 0.07169205\n",
      "Validation score: 0.831303\n",
      "Iteration 41, loss = 0.09529200\n",
      "Validation score: 0.767573\n",
      "Iteration 42, loss = 0.11778907\n",
      "Validation score: 0.826617\n",
      "Iteration 43, loss = 0.06319166\n",
      "Validation score: 0.757732\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "CPU times: user 1min 30s, sys: 7.26 s, total: 1min 37s\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit Data to Model\n",
    "model.fit(X_train_res_df, y_train_res)\n",
    "predictions = model.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6565"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Score\n",
    "model.score(test_feats, test_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4968435498058478"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure AUC-ROC\n",
    "roc_auc_score(test_lbl, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/safety_challenge.joblib.dat']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model to File\n",
    "model_fn = \"model/safety_challenge.joblib.dat\"\n",
    "joblib.dump(model, model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure From Holdout Data\n",
    "\n",
    "**For examiner:** Please save hold out data to `data/test/` folder with the same folder structure as the one provided for the challenge in `safety/` folder. Run cells below once the holdout data is in the suggested folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Holdout Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place data in directory data/\n",
    "FEATURES_HOLDOUT_PATH = 'data/test/features'\n",
    "LABELS_HOLDOUT_PATH = 'data/test/labels'\n",
    "\n",
    "# Load data\n",
    "features_holdout_df = load_from_directory(FEATURES_HOLDOUT_PATH)\n",
    "features_holdout_df = features_holdout_df.sort_values(['bookingID', 'second'])#.set_index('second')\n",
    "labels_holdout_df = load_from_directory(LABELS_HOLDOUT_PATH)\n",
    "\n",
    "# We groupby and sum labels to account for bookings with multiple labels (defaulting to dangerous)\n",
    "labels_holdout_df = labels_holdout_df.groupby('bookingID').max().reset_index()\n",
    "\n",
    "# Merge Holdout Data\n",
    "all_holdout_data = pd.merge(features_holdout_df, labels_holdout_df, on='bookingID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineer Data\n",
    "all_holdout_data['acceleration'] = (all_holdout_data['acceleration_x']**2 + \n",
    "                            all_holdout_data['acceleration_y']**2 + \n",
    "                            all_holdout_data['acceleration_z']**2).apply(lambda x: np.sqrt(x))\n",
    "\n",
    "all_holdout_data['gyro'] = (all_holdout_data['gyro_x']**2 + \n",
    "                            all_holdout_data['gyro_y']**2 + \n",
    "                            all_holdout_data['gyro_z']**2).apply(lambda x: np.sqrt(x))\n",
    "\n",
    "\n",
    "\n",
    "# Process holdout data\n",
    "holdout_features = process_data(all_holdout_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Saved Model\n",
    "loaded_model = joblib.load(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "holdout_predictions = loaded_model.predict(holdout_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5005791894491294"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure AUC-ROC\n",
    "roc_auc_score(labels_holdout_df.label, holdout_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
